{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf,col,rank\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "spark=SparkSession.builder.appName(\"UDF – Standardize Currency Columns\").getOrCreate()\n",
        "df=spark.read.csv(\"/content/top_100_saas_companies_2025.csv\",header=True,inferSchema=True)"
      ],
      "metadata": {
        "id": "ubph6D6WrtfZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "HuZrS-l06W9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae6bf445-1105-4665-abb6-da3ed1cf673d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+----------------+------+--------------------+-------------+--------------------+\n",
            "|Company Name|Valuation          |Valuation_values|ARR   |ARR_values          |Total Funding|Total_Funding_values|\n",
            "+------------+-------------------+----------------+------+--------------------+-------------+--------------------+\n",
            "|Microsoft   |$3T                |3.0E12          |$270B |2.7E11              |$1B          |1.0E9               |\n",
            "|Salesforce  |$227.8B            |2.278E11        |$37.9B|3.79E10             |$65.4M       |6.540000000000001E7 |\n",
            "|Adobe       |$240B              |2.4E11          |$19.4B|1.94E10             |$2.5M        |2500000.0           |\n",
            "|Oracle      |$350B              |3.5E11          |$52.9B|5.29E10             |$2K          |2000.0              |\n",
            "|SAP         |$215B              |2.15E11         |$32.5B|3.25E10             |N/A          |NULL                |\n",
            "|Intuit      |$180B              |1.8E11          |$14.4B|1.44E10             |$273M        |2.73E8              |\n",
            "|ServiceNow  |$147B              |1.47E11         |$8.9B |8.9E9               |$82.5M       |8.25E7              |\n",
            "|Workday     |$65B               |6.5E10          |$7.3B |7.3E9               |$249.9M      |2.499E8             |\n",
            "|Zoom        |$85B               |8.5E10          |$4.5B |4.5E9               |$145.5M      |1.455E8             |\n",
            "|Shopify     |$95B               |9.5E10          |$7.1B |7.1E9               |$122.3M      |1.223E8             |\n",
            "|Atlassian   |$55B               |5.5E10          |$3.5B |3.5E9               |$60M         |6.0E7               |\n",
            "|Snowflake   |$75B               |7.5E10          |$2.8B |2.8E9               |$1.4B        |1.4E9               |\n",
            "|HubSpot     |$32B               |3.2E10          |$2.2B |2.2E9               |$100.5M      |1.005E8             |\n",
            "|DocuSign    |$10B               |1.0E10          |$2.5B |2.5E9               |$514.3M      |5.1429999999999994E8|\n",
            "|Slack       |$27.7B (Salesforce)|2.77E10         |$1.7B |1.7E9               |$1.4B        |1.4E9               |\n",
            "|Notion      |$10B               |1.0E10          |$400M |4.0E8               |$353M        |3.53E8              |\n",
            "|Datadog     |$44B               |4.4E10          |$2.1B |2.1E9               |$147.9M      |1.479E8             |\n",
            "|MongoDB     |$26B               |2.6E10          |$1.7B |1.7E9               |$311.2M      |3.112E8             |\n",
            "|Okta        |$25B               |2.5E10          |$2.2B |2.2E9               |$230.5M      |2.305E8             |\n",
            "|Twilio      |$12B               |1.2E10          |$4.1B |4.0999999999999995E9|$261.3M      |2.613E8             |\n",
            "+------------+-------------------+----------------+------+--------------------+-------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf,col\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "spark=SparkSession.builder.appName(\"UDF – Standardize Currency Columns\").getOrCreate()\n",
        "df=spark.read.csv(\"/content/top_100_saas_companies_2025.csv\",header=True,inferSchema=True)\n",
        "\n",
        "\n",
        "def convert_to_values(k):\n",
        "  k=k.split()\n",
        "  k=str(k[0])\n",
        "  m=1.0\n",
        "  if k is None:\n",
        "    return None\n",
        "  if k=='N/A':\n",
        "    return None\n",
        "  if k[0]==\"$\":\n",
        "    k=k[1:]\n",
        "  if k.endswith(\"B\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000000\n",
        "\n",
        "  elif k.endswith(\"M\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000\n",
        "  elif k.endswith(\"T\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000000000\n",
        "  elif k.endswith(\"K\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000\n",
        "  return float(k)*m\n",
        "\n",
        "\n",
        "\n",
        "convert_to_values_udf=udf(convert_to_values,DoubleType())\n",
        "\n",
        "df=df.withColumn(\"ARR_values\",convert_to_values_udf(col(\"ARR\")))\n",
        "df=df.withColumn(\"Valuation_values\",convert_to_values_udf(col(\"Valuation\")))\n",
        "df=df.withColumn(\"Total_Funding_values\",convert_to_values_udf(col(\"Total Funding\")))\n",
        "\n",
        "df.select(\"Company Name\", \"Valuation\", \"Valuation_values\",\n",
        "                      \"ARR\", \"ARR_values\",\n",
        "                      \"Total Funding\", \"Total_Funding_values\").show(20, truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf,col,rank\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "spark=SparkSession.builder.appName(\"UDF – Standardize Currency Columns\").getOrCreate()\n",
        "df=spark.read.csv(\"/content/top_100_saas_companies_2025.csv\",header=True,inferSchema=True)\n",
        "\n",
        "\n",
        "def convert_to_values(k):\n",
        "  k=k.split()\n",
        "  k=str(k[0])\n",
        "  m=1.0\n",
        "  if k is None:\n",
        "    return None\n",
        "  if k=='N/A':\n",
        "    return None\n",
        "  if k[0]==\"$\":\n",
        "    k=k[1:]\n",
        "  if k.endswith(\"B\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000000\n",
        "\n",
        "  elif k.endswith(\"M\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000\n",
        "  elif k.endswith(\"T\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000000000000\n",
        "  elif k.endswith(\"K\"):\n",
        "    k=k[:-1]\n",
        "    m=m*1000\n",
        "  return float(k)*m\n",
        "\n",
        "\n",
        "\n",
        "convert_to_values_udf=udf(convert_to_values,DoubleType())\n",
        "df=df.withColumn(\"valuation_values\",convert_to_values_udf(col(\"Valuation\")))\n",
        "\n",
        "\n",
        "w=Window.partitionBy(\"industry\").orderBy(col(\"valuation_values\").desc())\n",
        "df = df.withColumn(\"Rank\", rank().over(w)) \\\n",
        "              .filter(col(\"Rank\") <= 2)\n",
        "\n",
        "\n",
        "df.select(\"Company Name\", \"Industry\", \"Valuation\", \"Valuation_values\", \"Rank\") \\\n",
        "         .orderBy(\"Industry\", \"Rank\") \\\n",
        "         .show(truncate=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuPHQFUnhbyW",
        "outputId": "f4236955-c2b5-4536-f55c-c1b3b80894f9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------------------+--------------+----------------+----+\n",
            "|Company Name|Industry              |Valuation     |Valuation_values|Rank|\n",
            "+------------+----------------------+--------------+----------------+----+\n",
            "|AppDynamics |APM                   |$3.7B (Cisco) |3.7E9           |1   |\n",
            "|Affirm      |BNPL                  |$12B          |1.2E10          |1   |\n",
            "|Looker      |Business Intelligence |$2.6B (Google)|2.6E9           |1   |\n",
            "|CircleCI    |CI/CD                 |$1.7B         |1.7E9           |1   |\n",
            "|Salesforce  |CRM                   |$227.8B       |2.278E11        |1   |\n",
            "|Marqeta     |Card Issuing          |$4.3B         |4.3E9           |1   |\n",
            "|Zscaler     |Cloud Security        |$30B          |3.0E10          |1   |\n",
            "|Netskope    |Cloud Security        |$7.5B         |7.5E9           |2   |\n",
            "|Dropbox     |Cloud Storage         |$8.5B         |8.5E9           |1   |\n",
            "|Box         |Cloud Storage         |$3.5B         |3.5E9           |2   |\n",
            "|Miro        |Collaboration         |$17.5B        |1.75E10         |1   |\n",
            "|Atlassian   |Collaboration Software|$55B          |5.5E10          |1   |\n",
            "|Twilio      |Communications        |$12B          |1.2E10          |1   |\n",
            "|RingCentral |Communications        |$5B           |5.0E9           |2   |\n",
            "|Procore     |Construction          |$9B           |9.0E9           |1   |\n",
            "|Five9       |Contact Center        |$8B           |8.0E9           |1   |\n",
            "|Brex        |Corporate Cards       |$12.3B        |1.23E10         |1   |\n",
            "|Adobe       |Creative Software     |$240B         |2.4E11          |1   |\n",
            "|Segment     |Customer Data         |$3.2B (Twilio)|3.2E9           |1   |\n",
            "|Braze       |Customer Engagement   |$5.6B         |5.6E9           |1   |\n",
            "+------------+----------------------+--------------+----------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, lag\n",
        "from pyspark.sql.types import DoubleType\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ARR Growth Gaps\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/top_100_saas_companies_2025.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "def parse_currency(k):\n",
        "    if k is None or k == 'N/A':\n",
        "        return None\n",
        "    k = k.strip()\n",
        "    multiplier = 1.0\n",
        "    if k.startswith(\"$\"):\n",
        "        k = k[1:]\n",
        "    if k.endswith(\"T\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000_000_000\n",
        "    elif k.endswith(\"B\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000_000\n",
        "    elif k.endswith(\"M\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000\n",
        "    elif k.endswith(\"K\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000\n",
        "    try:\n",
        "        return float(k) * multiplier\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "parse_currency_udf = udf(parse_currency, DoubleType())\n",
        "\n",
        "df = df.withColumn(\"ARR_Num\", parse_currency_udf(col(\"ARR\")))\n",
        "\n",
        "\n",
        "w = Window.partitionBy(\"Industry\").orderBy(col(\"ARR_Num\").desc())\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "df = df.withColumn(\"Prev_ARR\", lag(\"ARR_Num\").over(w))\n",
        "\n",
        "\n",
        "df = df.withColumn(\"ARR_Drop\", col(\"Prev_ARR\") - col(\"ARR_Num\"))\n",
        "\n",
        "\n",
        "df_filtered = df.filter(col(\"ARR_Drop\") > 1_000_000_000)\n",
        "\n",
        "\n",
        "df_filtered.select(\"Company Name\", \"Industry\", \"ARR\", \"ARR_Num\", \"Prev_ARR\", \"ARR_Drop\") \\\n",
        "           .orderBy(\"Industry\", \"ARR_Drop\", ascending=[True, False]) \\\n",
        "           .show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Vg3wIprkFN",
        "outputId": "f345784d-a2c4-433a-c06c-1c1df2fddcca"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+------+-------+--------------------+--------------------+\n",
            "|Company Name|Industry           |ARR   |ARR_Num|Prev_ARR            |ARR_Drop            |\n",
            "+------------+-------------------+------+-------+--------------------+--------------------+\n",
            "|Netskope    |Cloud Security     |$500M |5.0E8  |1.6E9               |1.1E9               |\n",
            "|Box         |Cloud Storage      |$1B   |1.0E9  |2.5E9               |1.5E9               |\n",
            "|RingCentral |Communications     |$2.2B |2.2E9  |4.0999999999999995E9|1.8999999999999995E9|\n",
            "|CrowdStrike |Cybersecurity      |$3.1B |3.1E9  |7.5E9               |4.4E9               |\n",
            "|Palantir    |Data Analytics     |$2.2B |2.2E9  |3.7E9               |1.5E9               |\n",
            "|Redis       |Database           |$100M |1.0E8  |1.7E9               |1.6E9               |\n",
            "|Figma       |Design             |$600M |6.0E8  |2.0E9               |1.4E9               |\n",
            "|SAP         |Enterprise Software|$32.5B|3.25E10|2.7E11              |2.375E11            |\n",
            "|Stripe      |Payments           |$14B  |1.4E10 |1.97E10             |5.7E9               |\n",
            "+------------+-------------------+------+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"G2 Rating Tier Classification\").getOrCreate()\n",
        "\n",
        "\n",
        "df = spark.read.csv(\"/content/top_100_saas_companies_2025.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "df = df.withColumn(\"Rating_Tier\",\n",
        "                   when(col(\"G2 Rating\") >= 4.7, \"Excellent\")\n",
        "                   .when((col(\"G2 Rating\") >= 4.3) & (col(\"G2 Rating\") < 4.7), \"Very Good\")\n",
        "                   .when((col(\"G2 Rating\") >= 4.0) & (col(\"G2 Rating\") < 4.3), \"Good\")\n",
        "                   .otherwise(\"Average\"))\n",
        "\n",
        "\n",
        "df.select(\"Company Name\", \"G2 Rating\", \"Rating_Tier\") \\\n",
        "  .orderBy(col(\"G2 Rating\").desc()) \\\n",
        "  .show(20, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp0yx1uLszfG",
        "outputId": "ecba029e-a18e-48e5-d4bd-98c187ed179e"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+-----------+\n",
            "|Company Name|G2 Rating|Rating_Tier|\n",
            "+------------+---------+-----------+\n",
            "|Rippling    |4.8      |Excellent  |\n",
            "|Ramp        |4.8      |Excellent  |\n",
            "|Miro        |4.7      |Excellent  |\n",
            "|Notion      |4.7      |Excellent  |\n",
            "|Figma       |4.7      |Excellent  |\n",
            "|Verkada     |4.7      |Excellent  |\n",
            "|Calendly    |4.7      |Excellent  |\n",
            "|CrowdStrike |4.7      |Excellent  |\n",
            "|Gong        |4.7      |Excellent  |\n",
            "|LaunchDarkly|4.7      |Excellent  |\n",
            "|Cloudflare  |4.7      |Excellent  |\n",
            "|Canva       |4.7      |Excellent  |\n",
            "|Navan       |4.7      |Excellent  |\n",
            "|Grammarly   |4.6      |Very Good  |\n",
            "|HashiCorp   |4.6      |Very Good  |\n",
            "|Monday.com  |4.6      |Very Good  |\n",
            "|Airtable    |4.6      |Very Good  |\n",
            "|Brex        |4.6      |Very Good  |\n",
            "|Klaviyo     |4.6      |Very Good  |\n",
            "|Benchling   |4.6      |Very Good  |\n",
            "+------------+---------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import split, col, trim\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Investor Tier Enrichment\").getOrCreate()\n",
        "\n",
        "\n",
        "df = spark.read.csv(\"/content/top_100_saas_companies_2025.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "investor_tiers = spark.createDataFrame([\n",
        "    (\"Accel\", \"Tier 1\"),\n",
        "    (\"Sequoia\", \"Tier 1\"),\n",
        "    (\"Andreessen Horowitz\", \"Tier 1\"),\n",
        "    (\"SoftBank\", \"Tier 2\"),\n",
        "    (\"Lightspeed\", \"Tier 2\"),\n",
        "    (\"Unknown\", \"Tier 3\")\n",
        "], [\"Investor\", \"Tier\"])\n",
        "\n",
        "\n",
        "df = df.withColumn(\"First_Investor\", trim(split(col(\"Top Investors\"), \",\")[0]))\n",
        "\n",
        "\n",
        "joined_df = df.join(investor_tiers, df[\"First_Investor\"] == investor_tiers[\"Investor\"], \"inner\")\n",
        "\n",
        "\n",
        "filtered_df = joined_df.filter(col(\"Tier\").isin(\"Tier 1\", \"Tier 2\"))\n",
        "\n",
        "\n",
        "result_df = filtered_df.select(\"Company Name\", \"First_Investor\", \"Tier\", \"Valuation\")\n",
        "\n",
        "\n",
        "result_df.orderBy(\"Tier\", \"Company Name\").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdJxYxOdtCtc",
        "outputId": "e0eb5c0f-1012-4e2b-ef7a-31814ac6e3ec"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-------------------+------+--------------------+\n",
            "|Company Name      |First_Investor     |Tier  |Valuation           |\n",
            "+------------------+-------------------+------+--------------------+\n",
            "|Algolia           |Accel              |Tier 1|$2.3B               |\n",
            "|Amplitude         |Sequoia            |Tier 1|$4B                 |\n",
            "|Canva             |Sequoia            |Tier 1|$40B                |\n",
            "|Carta             |Andreessen Horowitz|Tier 1|$7.4B               |\n",
            "|Confluent         |Sequoia            |Tier 1|$9.1B               |\n",
            "|Databricks        |Andreessen Horowitz|Tier 1|$43B                |\n",
            "|Dropbox           |Sequoia            |Tier 1|$8.5B               |\n",
            "|Freshworks        |Accel              |Tier 1|$5.2B               |\n",
            "|Gong              |Sequoia            |Tier 1|$7.3B               |\n",
            "|Mixpanel          |Andreessen Horowitz|Tier 1|$1.05B              |\n",
            "|MongoDB           |Sequoia            |Tier 1|$26B                |\n",
            "|Navan             |Andreessen Horowitz|Tier 1|$9.2B               |\n",
            "|Netskope          |Sequoia            |Tier 1|$7.5B               |\n",
            "|Okta              |Andreessen Horowitz|Tier 1|$25B                |\n",
            "|PagerDuty         |Andreessen Horowitz|Tier 1|$2.8B               |\n",
            "|Palo Alto Networks|Sequoia            |Tier 1|$95B                |\n",
            "|Qualtrics         |Sequoia            |Tier 1|$12.5B (Silver Lake)|\n",
            "|RingCentral       |Sequoia            |Tier 1|$5B                 |\n",
            "|Samsara           |Andreessen Horowitz|Tier 1|$12B                |\n",
            "|Segment           |Accel              |Tier 1|$3.2B (Twilio)      |\n",
            "+------------------+-------------------+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf, col, when\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "# Step 1: Start Spark session\n",
        "spark = SparkSession.builder.appName(\"Valuation vs Industry Median\").getOrCreate()\n",
        "\n",
        "# Step 2: Load SaaS company data\n",
        "df = spark.read.csv(\"/content/top_100_saas_companies_2025.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Step 3: Define currency parser UDF\n",
        "def parse_currency(k):\n",
        "    if k is None or k == 'N/A':\n",
        "        return None\n",
        "    k = k.strip()\n",
        "    multiplier = 1.0\n",
        "    if k.startswith(\"$\"):\n",
        "        k = k[1:]\n",
        "    if k.endswith(\"T\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000_000_000\n",
        "    elif k.endswith(\"B\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000_000\n",
        "    elif k.endswith(\"M\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000_000\n",
        "    elif k.endswith(\"K\"):\n",
        "        k = k[:-1]\n",
        "        multiplier = 1_000\n",
        "    try:\n",
        "        return float(k) * multiplier\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "parse_currency_udf = udf(parse_currency, DoubleType())\n",
        "\n",
        "df = df.withColumn(\"Valuation_values\", parse_currency_udf(col(\"Valuation\")))\n",
        "\n",
        "\n",
        "industry_medians = spark.createDataFrame([\n",
        "    (\"Enterprise Software\", 150_000_000_000),\n",
        "    (\"CRM\", 100_000_000_000),\n",
        "    (\"AI\", 70_000_000_000),\n",
        "    (\"HRTech\", 50_000_000_000),\n",
        "], [\"Industry\", \"Median_Valuation\"])\n",
        "\n",
        "\n",
        "joined_df = df.join(industry_medians, on=\"Industry\", how=\"inner\")\n",
        "\n",
        "\n",
        "joined_df = joined_df.withColumn(\n",
        "    \"Valuation_Position\",\n",
        "    when(col(\"Valuation_values\") > col(\"Median_Valuation\"), \"Above Median\")\n",
        "    .otherwise(\"Below Median\")\n",
        ")\n",
        "\n",
        "\n",
        "joined_df.select(\"Company Name\", \"Industry\", \"Valuation\", \"Valuation_values\", \"Median_Valuation\", \"Valuation_Position\") \\\n",
        "         .orderBy(\"Industry\", \"Valuation_values\", ascending=[True, False]) \\\n",
        "         .show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRIBxzbMt9w0",
        "outputId": "a2a9e9f6-dd1f-40fb-e0d7-657bea30041b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------------------+---------+----------------+----------------+------------------+\n",
            "|Company Name|Industry           |Valuation|Valuation_values|Median_Valuation|Valuation_Position|\n",
            "+------------+-------------------+---------+----------------+----------------+------------------+\n",
            "|Salesforce  |CRM                |$227.8B  |2.278E11        |100000000000    |Above Median      |\n",
            "|Microsoft   |Enterprise Software|$3T      |3.0E12          |150000000000    |Above Median      |\n",
            "|SAP         |Enterprise Software|$215B    |2.15E11         |150000000000    |Above Median      |\n",
            "+------------+-------------------+---------+----------------+----------------+------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}