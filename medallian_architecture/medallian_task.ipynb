{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f8ee2cc-09af-4158-81cc-3802ffb0b9c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+----------------+------+----------------+------+\n|transaction_id|customer_id|transaction_date|amount|product_category|region|\n+--------------+-----------+----------------+------+----------------+------+\n|          T001|      C1001|      2023-01-15|150.75|     Electronics|    US|\n|          T002|      C1002|      2023-01-16|  NULL|        Clothing|    UK|\n|          T003|      C1001|      2023-01-17| -25.0|     electronics|    US|\n|          T004|      C1003|      2023-01-18| 300.5|           Books|  NULL|\n|          T005|      C1002|      2023-01-18| 75.25|        CLOTHING|    UK|\n|          T006|      C1004|      2023-01-19| 200.0|           Books|    US|\n|          T007|      C1001|      2023-01-15|150.75|     Electronics|    US|\n|          T008|      C1005|      2023-01-20| 450.0| Home Appliances|    US|\n|          T009|      C1006|      2023-01-21| 89.99|     electronics|    UK|\n|          T010|      C1003|      2023-01-22| 120.0|           Books|    US|\n|          T011|      C1007|      2023-01-23| -10.5|        Clothing|  NULL|\n|          T012|      C1002|      2023-01-24|  65.3|        clothing|    UK|\n|          T013|      C1008|      2023-01-25|750.25|     Electronics|    US|\n|          T014|      C1004|      2023-01-26|  NULL|           Books|    US|\n|          T015|      C1009|      2023-01-27| 220.0| Home Appliances|    UK|\n|          T016|      C1010|      2023-01-28| 99.95|     Electronics|    US|\n|          T017|      C1001|      2023-01-29| 175.0|     electronics|    US|\n|          T018|      C1002|      2023-01-30|  45.0|        Clothing|    UK|\n|          T019|      C1003|      2023-01-31|280.75|           Books|    US|\n|          T020|      C1005|      2023-02-01| 600.0| Home Appliances|  NULL|\n+--------------+-----------+----------------+------+----------------+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "bronze_df = spark.read.table(\"workspace.default.customer_transactions_large\")\n",
    "\n",
    "bronze_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.customer_transactions_bronze\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.customer_transactions_bronze\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38a7199-c850-40f2-bcf1-50148f5fa915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+----------------+------+----------------+------+\n|transaction_id|customer_id|transaction_Date|amount|product_category|region|\n+--------------+-----------+----------------+------+----------------+------+\n|          T032|      C1007|      2023-02-13|  30.0|           Books|    UK|\n|          T048|      C1003|      2023-03-01| 340.0|           Books|    US|\n|          T044|      C1009|      2023-02-25|  20.0| Home Appliances|    UK|\n|          T007|      C1001|      2023-01-15|150.75|     Electronics|    US|\n|          T016|      C1010|      2023-01-28| 99.95|     Electronics|    US|\n|          T013|      C1008|      2023-01-25|750.25|     Electronics|    US|\n|          T042|      C1007|      2023-02-23|  95.0|     electronics|    UK|\n|          T015|      C1009|      2023-01-27| 220.0| Home Appliances|    UK|\n|          T001|      C1001|      2023-01-15|150.75|     Electronics|    US|\n|          T019|      C1003|      2023-01-31|280.75|           Books|    US|\n|          T006|      C1004|      2023-01-19| 200.0|           Books|    US|\n|          T047|      C1002|      2023-02-28| 70.25|        CLOTHING|    UK|\n|          T046|      C1001|      2023-02-27| 190.0|     Electronics|    US|\n|          T023|      C1008|      2023-02-04| 320.0|     electronics|    US|\n|          T033|      C1008|      2023-02-14| 550.0|     Electronics|    US|\n|          T041|      C1006|      2023-02-22| 110.0|        Clothing|    US|\n|          T035|      C1010|      2023-02-16| 210.0|           Books|    US|\n|          T026|      C1001|      2023-02-07|200.75|     Electronics|    US|\n|          T017|      C1001|      2023-01-29| 175.0|     electronics|    US|\n|          T043|      C1008|      2023-02-24| 420.0|           Books|    US|\n+--------------+-----------+----------------+------+----------------+------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, regexp_replace, when\n",
    "\n",
    "bronze_df = spark.read.table(\"workspace.default.customer_transactions_bronze\")\n",
    "\n",
    "silver_df = (\n",
    "    bronze_df\n",
    "    .withColumn(\"transaction_Date\", regexp_replace(col(\"transaction_date\"), \"-\", \"/\"))\n",
    "    .withColumn(\"transaction_Date\", to_date(col(\"transaction_Date\"), \"yyyy/MM/dd\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"amount\", when(col(\"amount\") < 0, -col(\"amount\")).otherwise(col(\"amount\")))\n",
    ")\n",
    "\n",
    "silver_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.customer_transactions_silver\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.customer_transactions_silver\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c929921-aa29-4abc-ac4a-502f6a7f37dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+------------------+---------------------+---------------------+\n|customer_id|total_transactions|total_amount_spent|avg_transaction_value|last_transaction_date|\n+-----------+------------------+------------------+---------------------+---------------------+\n|      C1003|                 4|           1050.75|             262.6875|           2023-03-01|\n|      C1010|                 4|            509.95|             127.4875|           2023-02-26|\n|      C1005|                 4|            1730.0|                432.5|           2023-03-03|\n|      C1002|                 5|             340.8|                68.16|           2023-02-28|\n|      C1007|                 3|            220.25|    73.41666666666667|           2023-02-23|\n|      C1006|                 4|            290.49|              72.6225|           2023-02-22|\n|      C1004|                 3|             555.0|                185.0|           2023-03-02|\n|      C1009|                 4|            510.75|             127.6875|           2023-02-25|\n|      C1001|                 7|            1058.0|   151.14285714285714|           2023-02-27|\n|      C1008|                 4|           2040.25|             510.0625|           2023-02-24|\n+-----------+------------------+------------------+---------------------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum, avg, max\n",
    "\n",
    "silver_df = spark.read.table(\"default.customer_transactions_silver\")\n",
    "\n",
    "gold_df = (\n",
    "    silver_df.groupBy(\"customer_id\")\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total_transactions\"),\n",
    "        sum(\"amount\").alias(\"total_amount_spent\"),\n",
    "        avg(\"amount\").alias(\"avg_transaction_value\"),\n",
    "        max(\"transaction_Date\").alias(\"last_transaction_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gold_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.customer_transactions_gold\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM default.customer_transactions_gold\").show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-07-09 15:03:01",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}